{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Documentación de haystackAI\n",
    "https://docs.haystack.deepset.ai/docs/components_overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "# logging.basicConfig(level=logging.DEBUG)\n",
    "# logging.basicConfig(level=logging.INFO)\n",
    "logging.basicConfig(level=logging.WARNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Demo seleccionando el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answer_builder': {'answers': [GeneratedAnswer(data='Rafael López Aliaga, conocido como \"Porky\", es un político y empresario peruano. Nació el 5 de enero de 1967 en Lima, Perú. Es conocido por ser el alcalde de Lima, cargo al que accedió en las elecciones municipales de 2022. López Aliaga se ha destacado por su postura conservadora y sus propuestas relacionadas con la economía y la seguridad. Además, ha sido una figura controversial en la política peruana, siendo objeto de críticas y elogios por su estilo de liderazgo y sus declaraciones públicas.', query='Quién es rafael lopez aliaga alias porky?', documents=[], meta={'model': 'gpt-4o-mini-2024-07-18', 'index': 0, 'finish_reason': 'stop', 'usage': {'completion_tokens': 113, 'prompt_tokens': 40, 'total_tokens': 153, 'completion_tokens_details': CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), 'prompt_tokens_details': PromptTokensDetails(audio_tokens=0, cached_tokens=0)}})]}}\n"
     ]
    }
   ],
   "source": [
    "from haystack import Pipeline\n",
    "from haystack.document_stores.in_memory import InMemoryDocumentStore\n",
    "from haystack.components.retrievers.in_memory import InMemoryBM25Retriever\n",
    "from haystack.components.generators import OpenAIGenerator\n",
    "from haystack.components.builders.answer_builder import AnswerBuilder\n",
    "from haystack.components.builders.prompt_builder import PromptBuilder\n",
    "from haystack.utils import Secret\n",
    "\n",
    "# Definición del template para construir prompts\n",
    "prompt_template = \"\"\"\n",
    "    Given these documents, answer the question.\\nDocuments:\n",
    "    {% for doc in documents %}\n",
    "        {{ doc.content }}\n",
    "    {% endfor %}\n",
    "\n",
    "    \\nQuestion: {{query}}\n",
    "    \\nAnswer:\n",
    "    \"\"\"\n",
    "\n",
    "# Crear pipeline\n",
    "p = Pipeline()\n",
    "\n",
    "# Agregar componentes\n",
    "p.add_component(instance=InMemoryBM25Retriever(document_store=InMemoryDocumentStore()), name=\"retriever\")\n",
    "p.add_component(instance=PromptBuilder(template=prompt_template), name=\"prompt_builder\")\n",
    "\n",
    "# Configuración del generador para usar un modelo específico\n",
    "p.add_component(\n",
    "    instance=OpenAIGenerator(\n",
    "        api_key=Secret.from_env_var(\"OPENAI_API_KEY\"),  # Clave API desde variable de entorno\n",
    "        model=\"gpt-4o-mini-2024-07-18\"  # Modelo específico\n",
    "    ),\n",
    "    name=\"llm\"\n",
    ")\n",
    "\n",
    "p.add_component(instance=AnswerBuilder(), name=\"answer_builder\")\n",
    "\n",
    "# Conectar componentes del pipeline\n",
    "p.connect(\"retriever\", \"prompt_builder.documents\")\n",
    "p.connect(\"prompt_builder\", \"llm\")\n",
    "p.connect(\"llm.replies\", \"answer_builder.replies\")\n",
    "p.connect(\"llm.meta\", \"answer_builder.meta\")\n",
    "p.connect(\"retriever\", \"answer_builder.documents\")\n",
    "\n",
    "# Definir consulta\n",
    "query = \"Quién es rafael lopez aliaga alias porky?\"\n",
    "\n",
    "# Ejecutar el pipeline\n",
    "result = p.run(\n",
    "    {\n",
    "        \"retriever\": {\"query\": query},\n",
    "        \"prompt_builder\": {\"query\": query},\n",
    "        \"answer_builder\": {\"query\": query},\n",
    "    }\n",
    ")\n",
    "\n",
    "# Imprimir el resultado\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Demo seleccionando el modelo por defecto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answer_builder': {'answers': [GeneratedAnswer(data='The capital of France is Paris.', query='What is the capital of France?', documents=[], meta={'model': 'gpt-4o-mini-2024-07-18', 'index': 0, 'finish_reason': 'stop', 'usage': {'completion_tokens': 7, 'prompt_tokens': 34, 'total_tokens': 41, 'completion_tokens_details': CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), 'prompt_tokens_details': PromptTokensDetails(audio_tokens=0, cached_tokens=0)}})]}}\n"
     ]
    }
   ],
   "source": [
    "from haystack import Pipeline\n",
    "from haystack.document_stores.in_memory import InMemoryDocumentStore\n",
    "from haystack.components.retrievers.in_memory import InMemoryBM25Retriever\n",
    "from haystack.components.generators import OpenAIGenerator\n",
    "from haystack.components.builders.answer_builder import AnswerBuilder\n",
    "from haystack.components.builders.prompt_builder import PromptBuilder\n",
    "from haystack.utils import Secret\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "    Given these documents, answer the question.\\nDocuments:\n",
    "    {% for doc in documents %}\n",
    "        {{ doc.content }}\n",
    "    {% endfor %}\n",
    "\n",
    "    \\nQuestion: {{query}}\n",
    "    \\nAnswer:\n",
    "    \"\"\"\n",
    "\n",
    "p = Pipeline()\n",
    "p.add_component(instance=InMemoryBM25Retriever(document_store=InMemoryDocumentStore()), name=\"retriever\")\n",
    "p.add_component(instance=PromptBuilder(template=prompt_template), name=\"prompt_builder\")\n",
    "p.add_component(instance=OpenAIGenerator(api_key=Secret.from_env_var(\"OPENAI_API_KEY\")), name=\"llm\")\n",
    "p.add_component(instance=AnswerBuilder(), name=\"answer_builder\")\n",
    "p.connect(\"retriever\", \"prompt_builder.documents\")\n",
    "p.connect(\"prompt_builder\", \"llm\")\n",
    "p.connect(\"llm.replies\", \"answer_builder.replies\")\n",
    "p.connect(\"llm.meta\", \"answer_builder.meta\")\n",
    "p.connect(\"retriever\", \"answer_builder.documents\")\n",
    "query = \"What is the capital of France?\"\n",
    "result = p.run(\n",
    "    {\n",
    "        \"retriever\": {\"query\": query},\n",
    "        \"prompt_builder\": {\"query\": query},\n",
    "        \"answer_builder\": {\"query\": query},\n",
    "    }\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Demo seleccionando con descripcion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answer_builder': {'answers': [GeneratedAnswer(data='The capital of France is Paris.', query='What is the capital of France?', documents=[], meta={'model': 'gpt-4o-mini-2024-07-18', 'index': 0, 'finish_reason': 'stop', 'usage': {'completion_tokens': 7, 'prompt_tokens': 34, 'total_tokens': 41, 'completion_tokens_details': CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), 'prompt_tokens_details': PromptTokensDetails(audio_tokens=0, cached_tokens=0)}})]}}\n"
     ]
    }
   ],
   "source": [
    "# Importación de componentes clave desde Haystack\n",
    "from haystack import Pipeline\n",
    "from haystack.document_stores.in_memory import InMemoryDocumentStore\n",
    "from haystack.components.retrievers.in_memory import InMemoryBM25Retriever\n",
    "from haystack.components.generators import OpenAIGenerator\n",
    "from haystack.components.builders.answer_builder import AnswerBuilder\n",
    "from haystack.components.builders.prompt_builder import PromptBuilder\n",
    "from haystack.utils import Secret\n",
    "\n",
    "# Definición de un template para construir prompts que serán enviados al modelo de lenguaje\n",
    "# Este prompt toma documentos y una pregunta como entrada y solicita una respuesta.\n",
    "prompt_template = \"\"\"\n",
    "    Given these documents, answer the question.\\nDocuments:\n",
    "    {% for doc in documents %}\n",
    "        {{ doc.content }}\n",
    "    {% endfor %}\n",
    "\n",
    "    \\nQuestion: {{query}}\n",
    "    \\nAnswer:\n",
    "    \"\"\"\n",
    "\n",
    "# Creación de un pipeline para conectar diferentes componentes\n",
    "p = Pipeline()\n",
    "\n",
    "# Agregando un componente de recuperación de documentos basado en BM25\n",
    "# Este componente buscará documentos relevantes en un almacén en memoria.\n",
    "p.add_component(instance=InMemoryBM25Retriever(document_store=InMemoryDocumentStore()), name=\"retriever\")\n",
    "\n",
    "# Agregando un PromptBuilder, que genera el prompt basado en el template y los documentos recuperados\n",
    "p.add_component(instance=PromptBuilder(template=prompt_template), name=\"prompt_builder\")\n",
    "\n",
    "# Agregando un generador (modelo de lenguaje) que utiliza OpenAI\n",
    "# La clave API se carga desde una variable de entorno utilizando Secret.from_env_var.\n",
    "p.add_component(instance=OpenAIGenerator(api_key=Secret.from_env_var(\"OPENAI_API_KEY\")), name=\"llm\")\n",
    "\n",
    "# Agregando un AnswerBuilder, que toma las respuestas generadas por el modelo\n",
    "# y las formatea en objetos GeneratedAnswer enriquecidos con datos como los documentos referenciados.\n",
    "p.add_component(instance=AnswerBuilder(), name=\"answer_builder\")\n",
    "\n",
    "# Conectando los componentes del pipeline para definir el flujo de datos.\n",
    "\n",
    "# Conexión del recuperador con el PromptBuilder: los documentos relevantes alimentan el prompt.\n",
    "p.connect(\"retriever\", \"prompt_builder.documents\")\n",
    "\n",
    "# Conexión del PromptBuilder con el generador: el prompt generado se envía al modelo de lenguaje.\n",
    "p.connect(\"prompt_builder\", \"llm\")\n",
    "\n",
    "# Conexión de las respuestas del generador al AnswerBuilder: las respuestas crudas son procesadas y formateadas.\n",
    "p.connect(\"llm.replies\", \"answer_builder.replies\")\n",
    "\n",
    "# Conexión de los metadatos generados por el modelo al AnswerBuilder: los metadatos enriquecen los objetos de respuesta.\n",
    "p.connect(\"llm.meta\", \"answer_builder.meta\")\n",
    "\n",
    "# Conexión de los documentos recuperados directamente al AnswerBuilder: los documentos ayudan a contextualizar las respuestas.\n",
    "p.connect(\"retriever\", \"answer_builder.documents\")\n",
    "\n",
    "# Definición de la consulta que se va a procesar\n",
    "query = \"What is the capital of France?\"\n",
    "\n",
    "# Ejecución del pipeline con la consulta, pasando datos necesarios a cada componente\n",
    "result = p.run(\n",
    "    {\n",
    "        \"retriever\": {\"query\": query},            # La consulta para recuperar documentos.\n",
    "        \"prompt_builder\": {\"query\": query},      # La consulta para construir el prompt.\n",
    "        \"answer_builder\": {\"query\": query},      # La consulta para contextualizar las respuestas.\n",
    "    }\n",
    ")\n",
    "\n",
    "# Imprime el resultado final generado por el pipeline\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is Paris.\n"
     ]
    }
   ],
   "source": [
    "response_data = result['answer_builder']['answers'][0].data\n",
    "print(response_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the capital of France?\n"
     ]
    }
   ],
   "source": [
    "query = result['answer_builder']['answers'][0].query\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "documents = result['answer_builder']['answers'][0].documents\n",
    "print(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'gpt-4o-mini-2024-07-18', 'index': 0, 'finish_reason': 'stop', 'usage': {'completion_tokens': 7, 'prompt_tokens': 34, 'total_tokens': 41, 'completion_tokens_details': CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), 'prompt_tokens_details': PromptTokensDetails(audio_tokens=0, cached_tokens=0)}}\n"
     ]
    }
   ],
   "source": [
    "meta = result['answer_builder']['answers'][0].meta\n",
    "print(meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-4o-mini-2024-07-18\n"
     ]
    }
   ],
   "source": [
    "model_used = meta['model']\n",
    "print(model_used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n"
     ]
    }
   ],
   "source": [
    "total_tokens = meta['usage']['total_tokens']\n",
    "print(total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: The capital of France is Paris.\n",
      "Query: What is the capital of France?\n",
      "Model: gpt-4o-mini-2024-07-18\n"
     ]
    }
   ],
   "source": [
    "for answer in result['answer_builder']['answers']:\n",
    "    print(f\"Response: {answer.data}\")\n",
    "    print(f\"Query: {answer.query}\")\n",
    "    print(f\"Model: {answer.meta['model']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_haystack_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
