{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solución **Lanchain**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if \"LANGCHAIN_API_KEY\" not in os.environ:\n",
    "    os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "    os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. Indexar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-4o-mini')\n",
    "embeddings = OpenAIEmbeddings(model='text-embedding-3-large')\n",
    "vector_store = InMemoryVectorStore(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se cargaron 175 documentos.\n",
      "Los documentos se dividieron en 769 fragmentos.\n",
      "Primeros 3 document IDs añadidos al vector store: ['e3fe9041-acf5-4868-a3a7-e4c9ae9ff197', 'd7f3ed82-3b8e-4ec7-b8e4-9d69604e0a29', 'a31c5a3a-7a8c-4e88-bfba-0e6cbe1c5b49']\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader, TextLoader, PyPDFLoader, CSVLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS  # Usa el vector store FAISS como ejemplo\n",
    "\n",
    "# Función para obtener el loader correspondiente según la extensión del archivo\n",
    "def get_loader(file_extension):\n",
    "    if file_extension == 'txt':\n",
    "        return TextLoader\n",
    "    elif file_extension == 'pdf':\n",
    "        return PyPDFLoader\n",
    "    elif file_extension == 'csv':\n",
    "        return CSVLoader\n",
    "    else:\n",
    "        raise ValueError(f\"Formato no soportado: {file_extension}\")\n",
    "\n",
    "# Definir directorio donde se encuentran los archivos\n",
    "DIRECTORY_PATH = './data'\n",
    "\n",
    "# Extensiones de archivo y sus loaders correspondientes\n",
    "SUPPORTED_FILE_TYPES = [\n",
    "    (\".txt\", TextLoader),\n",
    "    (\".pdf\", PyPDFLoader),\n",
    "    (\".csv\", CSVLoader)\n",
    "]\n",
    "\n",
    "# Crear una lista para almacenar los loaders configurados\n",
    "loaders = []\n",
    "\n",
    "# Configurar loaders para cada tipo de archivo soportado\n",
    "for extension, loader_class in SUPPORTED_FILE_TYPES:\n",
    "    loader = DirectoryLoader(\n",
    "        path=DIRECTORY_PATH,\n",
    "        glob=f\"**/*{extension}\",\n",
    "        loader_cls=loader_class\n",
    "    )\n",
    "    loaders.append(loader)\n",
    "\n",
    "# Lista para almacenar los documentos cargados\n",
    "documents = []\n",
    "\n",
    "# Cargar documentos usando cada loader\n",
    "for loader in loaders:\n",
    "    loaded_documents = loader.load()\n",
    "    documents.extend(loaded_documents)\n",
    "\n",
    "# Imprimir información básica de los documentos cargados\n",
    "print(f\"Se cargaron {len(documents)} documentos.\")\n",
    "\n",
    "# Dividir documentos en fragmentos con RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,  # Tamaño de cada fragmento (en caracteres)\n",
    "    chunk_overlap=200,  # Superposición entre fragmentos (en caracteres)\n",
    "    add_start_index=True  # Agregar el índice de inicio en el documento original\n",
    ")\n",
    "\n",
    "# Dividir los documentos en fragmentos más pequeños\n",
    "all_splits = text_splitter.split_documents(documents)\n",
    "\n",
    "print(f\"Los documentos se dividieron en {len(all_splits)} fragmentos.\")\n",
    "\n",
    "# Agregar los fragmentos al vector store\n",
    "document_ids = vector_store.add_documents(documents=all_splits)\n",
    "\n",
    "# Imprimir los primeros tres IDs de documentos añadidos al vector store\n",
    "print(\"Primeros 3 document IDs añadidos al vector store:\", document_ids[:3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Retrieval and Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
      "Question: (question goes here) \n",
      "Context: (context goes here) \n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "example_messages = prompt.invoke(\n",
    "    {\"context\": \"(context goes here)\", \"question\": \"(question goes here)\"}\n",
    ").to_messages()\n",
    "\n",
    "assert len(example_messages) == 1\n",
    "print(example_messages[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
