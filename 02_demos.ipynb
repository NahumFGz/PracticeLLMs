{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo 1: \n",
    "\n",
    "- Sistema de preguntas y respuestas con un pipeline simple con un lector y un buscador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating BM25 representation...: 100%|██████████| 3/3 [00:00<00:00, 41803.69 docs/s]\n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00,  2.40 Batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Respuestas:\n",
      "Respuesta: Lima, Puntuación: 0.9510083198547363\n",
      "Respuesta: El Machu Picchu, Puntuación: 0.19514483213424683\n",
      "Respuesta: El Amazonas, Puntuación: 0.08661656826734543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import FARMReader, BM25Retriever\n",
    "from haystack.pipelines import ExtractiveQAPipeline\n",
    "from haystack.document_stores import InMemoryDocumentStore\n",
    "\n",
    "# Paso 1: Configurar el DocumentStore con BM25 habilitado\n",
    "document_store = InMemoryDocumentStore(use_bm25=True)\n",
    "\n",
    "# Paso 2: Agregar documentos al DocumentStore\n",
    "documents = [\n",
    "    {\"content\": \"Lima es la capital de Perú.\", \"meta\": {\"source\": \"Wikipedia\"}},\n",
    "    {\"content\": \"El Machu Picchu es una de las maravillas del mundo.\", \"meta\": {\"source\": \"Wikipedia\"}},\n",
    "    {\"content\": \"El Amazonas es el río más caudaloso del mundo.\", \"meta\": {\"source\": \"Wikipedia\"}},\n",
    "]\n",
    "document_store.write_documents(documents)\n",
    "\n",
    "# Paso 3: Configurar un Retriever (BM25 en este caso)\n",
    "retriever = BM25Retriever(document_store=document_store)\n",
    "\n",
    "# Paso 4: Configurar un Reader (modelo preentrenado)\n",
    "reader = FARMReader(model_name_or_path=\"deepset/roberta-base-squad2\")\n",
    "\n",
    "# Paso 5: Crear un pipeline de preguntas y respuestas\n",
    "pipeline = ExtractiveQAPipeline(reader=reader, retriever=retriever)\n",
    "\n",
    "# Paso 6: Realizar una consulta\n",
    "query = \"¿Cuál es la capital de Perú?\"\n",
    "result = pipeline.run(query=query, params={\"Retriever\": {\"top_k\": 10}, \"Reader\": {\"top_k\": 3}})\n",
    "\n",
    "# Paso 7: Imprimir resultados\n",
    "print(\"Respuestas:\")\n",
    "for answer in result[\"answers\"]:\n",
    "    print(f\"Respuesta: {answer.answer}, Puntuación: {answer.score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo 2:\n",
    "- Busqueda semántica en documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing Documents: 10000it [00:00, 1263496.81it/s]      \n",
      "Documents Processed: 10000 docs [00:00, 260365.38 docs/s]    \n",
      "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 35.41 Batches/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Respuestas:\n",
      "Respuesta: tecnológica, Puntuación: 0.3722141683101654\n",
      "Respuesta: gran potencial, Puntuación: 0.042410317808389664\n",
      "Respuesta: ChatGPT pueden responder preguntas y generar texto., Puntuación: 0.0036275871098041534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from haystack.nodes import DensePassageRetriever, FARMReader\n",
    "from haystack.pipelines import ExtractiveQAPipeline\n",
    "from haystack.document_stores import FAISSDocumentStore\n",
    "\n",
    "# Paso 1: Configurar el DocumentStore\n",
    "document_store = FAISSDocumentStore(faiss_index_factory_str=\"Flat\")\n",
    "\n",
    "# Paso 2: Agregar documentos al DocumentStore\n",
    "documents = [\n",
    "    {\"content\": \"La inteligencia artificial está transformando la industria tecnológica.\", \"meta\": {\"source\": \"Artículo 1\"}},\n",
    "    {\"content\": \"Los modelos de lenguaje como ChatGPT pueden responder preguntas y generar texto.\", \"meta\": {\"source\": \"Artículo 2\"}},\n",
    "    {\"content\": \"La computación cuántica es una tecnología emergente con gran potencial.\", \"meta\": {\"source\": \"Artículo 3\"}},\n",
    "]\n",
    "document_store.write_documents(documents)\n",
    "\n",
    "# Paso 3: Configurar el Retriever denso\n",
    "retriever = DensePassageRetriever(\n",
    "    document_store=document_store,\n",
    "    query_embedding_model=\"facebook/dpr-question_encoder-single-nq-base\",\n",
    "    passage_embedding_model=\"facebook/dpr-ctx_encoder-single-nq-base\",\n",
    "    use_gpu=True\n",
    ")\n",
    "\n",
    "# Paso 4: Actualizar representaciones de los documentos\n",
    "document_store.update_embeddings(retriever)\n",
    "\n",
    "# Paso 5: Configurar un Reader\n",
    "reader = FARMReader(model_name_or_path=\"deepset/roberta-base-squad2\")\n",
    "\n",
    "# Paso 6: Crear el pipeline\n",
    "pipeline = ExtractiveQAPipeline(reader=reader, retriever=retriever)\n",
    "\n",
    "# Paso 7: Realizar una consulta\n",
    "query = \"¿Qué está haciendo la inteligencia artificial en la industria?\"\n",
    "result = pipeline.run(query=query, params={\"Retriever\": {\"top_k\": 10}, \"Reader\": {\"top_k\": 3}})\n",
    "\n",
    "# Paso 8: Imprimir resultados\n",
    "print(\"Respuestas:\")\n",
    "for answer in result[\"answers\"]:\n",
    "    print(f\"Respuesta: {answer.answer}, Puntuación: {answer.score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_haystack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
