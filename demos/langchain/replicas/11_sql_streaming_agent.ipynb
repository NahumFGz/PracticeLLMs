{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if \"LANGCHAIN_API_KEY\" not in os.environ:\n",
    "    os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "    os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. Datos de ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sqlite\n",
      "['Album', 'Artist', 'Customer', 'Employee', 'Genre', 'Invoice', 'InvoiceLine', 'MediaType', 'Playlist', 'PlaylistTrack', 'Track']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"[(1, 'AC/DC'), (2, 'Accept'), (3, 'Aerosmith'), (4, 'Alanis Morissette'), (5, 'Alice In Chains'), (6, 'Antônio Carlos Jobim'), (7, 'Apocalyptica'), (8, 'Audioslave'), (9, 'BackBeat'), (10, 'Billy Cobham')]\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.utilities import SQLDatabase\n",
    "\n",
    "db = SQLDatabase.from_uri(\"sqlite:///Chinook.db\")\n",
    "print(db.dialect)\n",
    "print(db.get_usable_table_names())\n",
    "db.run(\"SELECT * FROM Artist LIMIT 10;\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Replica con TypedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict, Annotated\n",
    "\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    query: str\n",
    "    result: str\n",
    "    answer: str\n",
    "\n",
    "class QueryOutput(TypedDict):\n",
    "    query: Annotated[str, ..., \"Syntactically valid SQL query\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "\n",
      "Given an input question, create a syntactically correct \u001b[33;1m\u001b[1;3m{dialect}\u001b[0m query to run to help find the answer. Unless the user specifies in his question a specific number of examples they wish to obtain, always limit your query to at most \u001b[33;1m\u001b[1;3m{top_k}\u001b[0m results. You can order the results by a relevant column to return the most interesting examples in the database.\n",
      "\n",
      "Never query for all the columns from a specific table, only ask for a the few relevant columns given the question.\n",
      "\n",
      "Pay attention to use only the column names that you can see in the schema description. Be careful to not query for columns that do not exist. Also, pay attention to which column is in which table.\n",
      "\n",
      "Only use the following tables:\n",
      "\u001b[33;1m\u001b[1;3m{table_info}\u001b[0m\n",
      "\n",
      "Question: \u001b[33;1m\u001b[1;3m{input}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-4o-mini')\n",
    "\n",
    "query_prompt_template = hub.pull(\"langchain-ai/sql-query-system-prompt\")\n",
    "assert len(query_prompt_template.messages) == 1\n",
    "query_prompt_template[0].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "from typing import Any\n",
    "import json\n",
    "from pydantic import ValidationError, BaseModel\n",
    "\n",
    "class QueryOutput(BaseModel):\n",
    "    query: str\n",
    "\n",
    "def write_query_streaming(state: State):\n",
    "    \"\"\"\n",
    "    Genera un SQL query en streaming basado en el estado proporcionado\n",
    "    y valida el resultado con un esquema estructurado.\n",
    "    \"\"\"\n",
    "    # Crear el prompt inicial\n",
    "    prompt = query_prompt_template.invoke({\n",
    "        \"dialect\": db.dialect,\n",
    "        \"top_k\": 10,\n",
    "        \"table_info\": db.get_table_info(),\n",
    "        \"input\": state[\"question\"],\n",
    "    })\n",
    "\n",
    "    # Configuración del modelo en streaming\n",
    "    streaming_llm = ChatOpenAI(model=\"gpt-4o-mini\", streaming=True)\n",
    "\n",
    "    # Acumular resultado de streaming\n",
    "    raw_output = \"\"\n",
    "    print(\"Generando query en streaming:\")\n",
    "    for token in streaming_llm.stream(prompt):\n",
    "        raw_output += token.content  # Concatenar el contenido del token\n",
    "        print(token.content, end=\"\")  # Mostrar token en tiempo real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando query en streaming:\n",
      "```sql\n",
      "SELECT COUNT(*) AS TotalEmployees FROM Employee;\n",
      "```"
     ]
    }
   ],
   "source": [
    "write_query_streaming({\"question\": \"Cuantos empleados hay?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_query_streaming(state: State):\n",
    "    \"\"\"\n",
    "    Genera un SQL query en streaming basado en el estado proporcionado\n",
    "    y valida el resultado con un esquema estructurado.\n",
    "    \"\"\"\n",
    "    prompt = query_prompt_template.invoke({\n",
    "        \"dialect\": db.dialect,\n",
    "        \"top_k\": 10,\n",
    "        \"table_info\": db.get_table_info(),\n",
    "        \"input\": state[\"question\"],\n",
    "    })\n",
    "\n",
    "    # Configuración del modelo con streaming\n",
    "    streaming_llm = ChatOpenAI(model=\"gpt-4o-mini\", streaming=True)\n",
    "\n",
    "    # Acumular el resultado generado\n",
    "    raw_output = \"\"\n",
    "    print(\"Generando respuesta en streaming:\")\n",
    "    for token in streaming_llm.stream(prompt):\n",
    "        raw_output += token.content\n",
    "        print(token.content, end=\"\")  # Mostrar en tiempo real\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando respuesta en streaming:\n",
      "```sql\n",
      "SELECT COUNT(*) AS TotalEmployees FROM Employee;\n",
      "```"
     ]
    }
   ],
   "source": [
    "write_query_streaming({\"question\": \"Cuantos empleados hay?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_query_structured(state: State):\n",
    "    \"\"\"\n",
    "    Genera un SQL query usando with_structured_output para validación automática.\n",
    "    \"\"\"\n",
    "    prompt = query_prompt_template.invoke({\n",
    "        \"dialect\": db.dialect,\n",
    "        \"top_k\": 10,\n",
    "        \"table_info\": db.get_table_info(),\n",
    "        \"input\": state[\"question\"],\n",
    "    })\n",
    "\n",
    "    # Configuración de LLM con esquema estructurado\n",
    "    structured_llm = llm.with_structured_output(QueryOutput)\n",
    "\n",
    "    # Invocación del modelo\n",
    "    result = structured_llm.invoke(prompt)\n",
    "\n",
    "    # Acceso al atributo query del objeto\n",
    "    return result.query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SELECT COUNT(*) AS TotalEmployees FROM Employee;'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "write_query_structured({\"question\": \"Cuantos empleados hay?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Limpiar streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_streamed_output(raw_output: str) -> str:\n",
    "    \"\"\"\n",
    "    Limpia los decoradores de bloques de código (como ```sql) de un texto.\n",
    "    \"\"\"\n",
    "    # Elimina bloques de código como ```sql y ```\n",
    "    cleaned_output = re.sub(r\"```[\\w]*\\n|```\", \"\", raw_output).strip()\n",
    "    return cleaned_output\n",
    "\n",
    "def write_query_streaming(state: State):\n",
    "    \"\"\"\n",
    "    Genera un SQL query en streaming basado en el estado proporcionado.\n",
    "    \"\"\"\n",
    "    prompt = query_prompt_template.invoke({\n",
    "        \"dialect\": db.dialect,\n",
    "        \"top_k\": 10,\n",
    "        \"table_info\": db.get_table_info(),\n",
    "        \"input\": state[\"question\"],\n",
    "    })\n",
    "\n",
    "    # Configuración del modelo con streaming\n",
    "    streaming_llm = ChatOpenAI(model=\"gpt-4o-mini\", streaming=True)\n",
    "\n",
    "    # Acumular el resultado generado\n",
    "    raw_output = \"\"\n",
    "    print(\"Generando respuesta en streaming:\")\n",
    "    for token in streaming_llm.stream(prompt):\n",
    "        raw_output += token.content\n",
    "        print(token.content, end=\"\")  # Mostrar en tiempo real\n",
    "\n",
    "    print(\"\\n\\nLimpieza de la salida...\")\n",
    "    cleaned_output = clean_streamed_output(raw_output)\n",
    "\n",
    "    print(\"\\nQuery limpio:\")\n",
    "    print(cleaned_output)\n",
    "    return cleaned_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando respuesta en streaming:\n",
      "```sql\n",
      "SELECT COUNT(*) AS TotalArtists \n",
      "FROM Artist \n",
      "WHERE Name LIKE 'A%';\n",
      "```\n",
      "\n",
      "Limpieza de la salida...\n",
      "\n",
      "Query limpio:\n",
      "SELECT COUNT(*) AS TotalArtists \n",
      "FROM Artist \n",
      "WHERE Name LIKE 'A%';\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"SELECT COUNT(*) AS TotalArtists \\nFROM Artist \\nWHERE Name LIKE 'A%';\""
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "write_query_streaming({\"question\": \"Cuantos que su nombre inicia con A existen?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
