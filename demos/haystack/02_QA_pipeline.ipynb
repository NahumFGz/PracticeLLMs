{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Primer pipeline con RAG](https://haystack.deepset.ai/tutorials/27_first_rag_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Obtenci√≥n e indexaci√≥n de documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! Solo es para haystack sepa que tutorial se esta ejecutando\n",
    "from haystack.telemetry import tutorial_running\n",
    "tutorial_running(27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar el DocumentStore\n",
    "from haystack.document_stores.in_memory import InMemoryDocumentStore\n",
    "\n",
    "document_store = InMemoryDocumentStore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener los datos de ejemplo\n",
    "from datasets import load_dataset\n",
    "from haystack import Document\n",
    "\n",
    "dataset = load_dataset(\"bilgeyucel/seven-wonders\", split=\"train\")\n",
    "docs = [Document(content=doc[\"content\"], meta=doc[\"meta\"]) for doc in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar Embedder\n",
    "from haystack.components.embedders import SentenceTransformersDocumentEmbedder\n",
    "\n",
    "doc_embedder = SentenceTransformersDocumentEmbedder(model='sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "# Descargar el modelo\n",
    "doc_embedder.warm_up()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64f4a0605d824c6c86181c683db910c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Indexar los documentos\n",
    "docs_with_embeddings = doc_embedder.run(docs)\n",
    "#docs_with_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Escribir documentos en el DocumentStore\n",
    "document_store.write_documents(docs_with_embeddings[\"documents\"])\n",
    "\n",
    "# Mostrar los documentos indexados\n",
    "# document_store.filter_documents()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Construyendo el RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar el Text Embedder, se debe usar el mimo modelo con el que se crearon los embeddings\n",
    "from haystack.components.embedders import SentenceTransformersTextEmbedder\n",
    "\n",
    "text_embedder = SentenceTransformersTextEmbedder(model='sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iniciar el recuperador -> este retriver obtendr√° los documentos relevantes para una consulta\n",
    "from haystack.components.retrievers.in_memory import InMemoryEmbeddingRetriever\n",
    "\n",
    "retriver = InMemoryEmbeddingRetriever(document_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir una platilla para el prompt\n",
    "from haystack.components.builders import PromptBuilder\n",
    "\n",
    "template = \"\"\"\n",
    "Given the following information, answer the question.\n",
    "\n",
    "Context:\n",
    "{% for document in documents %}\n",
    "    {{ document.content }}\n",
    "{% endfor %}\n",
    "\n",
    "Question: {{question}}\n",
    "Answer:\n",
    "\"\"\"\n",
    "prompt_builder = PromptBuilder(template=template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<haystack.components.builders.prompt_builder.PromptBuilder object at 0x7fcd35b0d8d0>\n",
       "Inputs:\n",
       "  - documents: Any\n",
       "  - question: Any\n",
       "  - template: Optional[str]\n",
       "  - template_variables: Optional[Dict[str, Any]]\n",
       "Outputs:\n",
       "  - prompt: str"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar un generador\n",
    "from haystack.utils import Secret\n",
    "from haystack.components.generators import OpenAIGenerator\n",
    "\n",
    "generator = OpenAIGenerator(\n",
    "                            api_key=Secret.from_env_var(\"OPENAI_API_KEY\"),\n",
    "                            model=\"gpt-4o-mini-2024-07-18\"\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<haystack.core.pipeline.pipeline.Pipeline object at 0x7fcd280390d0>\n",
       "üöÖ Components\n",
       "  - text_embedder: SentenceTransformersTextEmbedder\n",
       "  - retriever: InMemoryEmbeddingRetriever\n",
       "  - prompt_builder: PromptBuilder\n",
       "  - llm: OpenAIGenerator\n",
       "üõ§Ô∏è Connections\n",
       "  - text_embedder.embedding -> retriever.query_embedding (List[float])\n",
       "  - retriever.documents -> prompt_builder.documents (List[Document])\n",
       "  - prompt_builder.prompt -> llm.prompt (str)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construir el pipeline\n",
    "from haystack import Pipeline\n",
    "\n",
    "basic_rag_pipeline = Pipeline()\n",
    "\n",
    "# Agregar los componentes al pipeline\n",
    "basic_rag_pipeline.add_component(\"text_embedder\", text_embedder)\n",
    "basic_rag_pipeline.add_component(\"retriever\", retriver)\n",
    "basic_rag_pipeline.add_component(\"prompt_builder\", prompt_builder)\n",
    "basic_rag_pipeline.add_component(\"llm\", generator)\n",
    "\n",
    "# Conectar los componentes entre s√≠\n",
    "basic_rag_pipeline.connect(\"text_embedder.embedding\", \"retriever.query_embedding\")\n",
    "basic_rag_pipeline.connect(\"retriever\", \"prompt_builder.documents\")\n",
    "basic_rag_pipeline.connect(\"prompt_builder\", \"llm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f549b319fbb14b57a7da9e9d2939b7a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Colossus of Rhodes was a statue of the Greek sun-god Helios, standing approximately 70 cubits, or about 33 meters (108 feet) tall. According to ancient accounts, it was constructed with iron tie bars covered by brass plates that formed the skin of the statue. The interior of the statue was filled with stone blocks as construction progressed.\n",
      "\n",
      "While scholars lack detailed accounts of its full appearance, they have a general idea based on contemporary depictions of Helios. The head of the statue was likely adorned with curly hair and had evenly spaced spikes, which represented rays of sunlight. These features are similar to images found on coins from Rhodes dating back to that period.\n",
      "\n",
      "The Colossus was said to stand on a 15-meter-high (49-foot) white marble pedestal at the entrance of Rhodes' harbor. The statue itself was designed in a manner that conveyed a sense of grandeur and power, celebrating the Rhodians' victory and independence after defending their city against an attack. Although the exact details of its pose and expression are not definitively known, the statue likely embodied the divine and triumphant nature of Helios.\n"
     ]
    }
   ],
   "source": [
    "question = \"What does Rhodes Statue look like?\"\n",
    "\n",
    "response = basic_rag_pipeline.run({\"text_embedder\": {\"text\": question}, \"prompt_builder\": {\"question\": question}})\n",
    "\n",
    "print(response[\"llm\"][\"replies\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    \"Where is Gardens of Babylon?\",\n",
    "    \"Why did people build Great Pyramid of Giza?\",\n",
    "    \"What does Rhodes Statue look like?\",\n",
    "    \"Why did people visit the Temple of Artemis?\",\n",
    "    \"What is the importance of Colossus of Rhodes?\",\n",
    "    \"What happened to the Tomb of Mausolus?\",\n",
    "    \"How did Colossus of Rhodes collapse?\",\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_haystack_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
