{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Preprocessing Different File Types](https://haystack.deepset.ai/tutorials/30_file_type_preprocessing_index_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! Solo es para haystack sepa que tutorial se esta ejecutando\n",
    "from haystack.telemetry import tutorial_running\n",
    "tutorial_running(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Descargar los archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gdown\n",
    "\n",
    "url = \"https://drive.google.com/drive/folders/1n9yqq5Gl_HWfND5bTlrCwAOycMDt5EMj\"\n",
    "output_dir = \"recipe_files\"\n",
    "\n",
    "# gdown.download_folder(url, quiet=True, output=output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Crear un pipeline para indexar documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.components.writers import DocumentWriter\n",
    "from haystack.components.converters import MarkdownToDocument, PyPDFToDocument, TextFileToDocument\n",
    "from haystack.components.preprocessors import DocumentSplitter, DocumentCleaner\n",
    "from haystack.components.routers import FileTypeRouter\n",
    "from haystack.components.joiners import DocumentJoiner\n",
    "from haystack.components.embedders import SentenceTransformersDocumentEmbedder\n",
    "from haystack import Pipeline\n",
    "from haystack.document_stores.in_memory import InMemoryDocumentStore\n",
    "\n",
    "document_store = InMemoryDocumentStore()\n",
    "file_type_router = FileTypeRouter(mime_types=[\"text/plain\", \"application/pdf\", \"text/markdown\"])\n",
    "text_file_converter = TextFileToDocument()\n",
    "markdown_converter = MarkdownToDocument()\n",
    "pdf_converter = PyPDFToDocument()\n",
    "document_joiner = DocumentJoiner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A partir de ah√≠, los pasos para este proceso de indexaci√≥n son un poco m√°s est√°ndar. DocumentCleanerSe eliminan los espacios en blanco y luego DocumentSplitterse dividen en fragmentos de 150 palabras, con un poco de superposici√≥n para evitar perder contexto.\n",
    "\"\"\"\n",
    "\n",
    "document_cleaner = DocumentCleaner()\n",
    "document_splitter = DocumentSplitter(split_by=\"word\", split_length=150, split_overlap=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora, agregar√° un SentenceTransformersDocumentEmbedderpara crear incrustaciones a partir de los documentos\n",
    "document_embedder = SentenceTransformersDocumentEmbedder(model=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "document_writer = DocumentWriter(document_store=document_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear pipeline\n",
    "preprocessing_pipeline = Pipeline()\n",
    "preprocessing_pipeline.add_component(instance=file_type_router, name=\"file_type_router\")\n",
    "preprocessing_pipeline.add_component(instance=text_file_converter, name=\"text_file_converter\")\n",
    "preprocessing_pipeline.add_component(instance=markdown_converter, name=\"markdown_converter\")\n",
    "preprocessing_pipeline.add_component(instance=pdf_converter, name=\"pypdf_converter\")\n",
    "preprocessing_pipeline.add_component(instance=document_joiner, name=\"document_joiner\")\n",
    "preprocessing_pipeline.add_component(instance=document_cleaner, name=\"document_cleaner\")\n",
    "preprocessing_pipeline.add_component(instance=document_splitter, name=\"document_splitter\")\n",
    "preprocessing_pipeline.add_component(instance=document_embedder, name=\"document_embedder\")\n",
    "preprocessing_pipeline.add_component(instance=document_writer, name=\"document_writer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<haystack.core.pipeline.pipeline.Pipeline object at 0x7f4aaa8fe090>\n",
       "üöÖ Components\n",
       "  - file_type_router: FileTypeRouter\n",
       "  - text_file_converter: TextFileToDocument\n",
       "  - markdown_converter: MarkdownToDocument\n",
       "  - pypdf_converter: PyPDFToDocument\n",
       "  - document_joiner: DocumentJoiner\n",
       "  - document_cleaner: DocumentCleaner\n",
       "  - document_splitter: DocumentSplitter\n",
       "  - document_embedder: SentenceTransformersDocumentEmbedder\n",
       "  - document_writer: DocumentWriter\n",
       "üõ§Ô∏è Connections\n",
       "  - file_type_router.text/plain -> text_file_converter.sources (List[Union[str, Path, ByteStream]])\n",
       "  - file_type_router.application/pdf -> pypdf_converter.sources (List[Union[str, Path, ByteStream]])\n",
       "  - file_type_router.text/markdown -> markdown_converter.sources (List[Union[str, Path, ByteStream]])\n",
       "  - text_file_converter.documents -> document_joiner.documents (List[Document])\n",
       "  - markdown_converter.documents -> document_joiner.documents (List[Document])\n",
       "  - pypdf_converter.documents -> document_joiner.documents (List[Document])\n",
       "  - document_joiner.documents -> document_cleaner.documents (List[Document])\n",
       "  - document_cleaner.documents -> document_splitter.documents (List[Document])\n",
       "  - document_splitter.documents -> document_embedder.documents (List[Document])\n",
       "  - document_embedder.documents -> document_writer.documents (List[Document])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Conectar pipelines\n",
    "preprocessing_pipeline.connect(\"file_type_router.text/plain\", \"text_file_converter.sources\")\n",
    "preprocessing_pipeline.connect(\"file_type_router.application/pdf\", \"pypdf_converter.sources\")\n",
    "preprocessing_pipeline.connect(\"file_type_router.text/markdown\", \"markdown_converter.sources\")\n",
    "preprocessing_pipeline.connect(\"text_file_converter\", \"document_joiner\")\n",
    "preprocessing_pipeline.connect(\"pypdf_converter\", \"document_joiner\")\n",
    "preprocessing_pipeline.connect(\"markdown_converter\", \"document_joiner\")\n",
    "preprocessing_pipeline.connect(\"document_joiner\", \"document_cleaner\")\n",
    "preprocessing_pipeline.connect(\"document_cleaner\", \"document_splitter\")\n",
    "preprocessing_pipeline.connect(\"document_splitter\", \"document_embedder\")\n",
    "preprocessing_pipeline.connect(\"document_embedder\", \"document_writer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing_pipeline.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting markdown files to Documents: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 876.19it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2516bf45af484346af3d8533f6df3b70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'document_writer': {'documents_written': 14}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "preprocessing_pipeline.run({\"file_type_router\": {\"sources\": list(Path(output_dir).glob(\"**/*\"))}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. **Opcional** - Crear una canalizaci√≥n para consultar documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construir un RAG apra responder a las preguntas en funci√≥n a los documentos indexados\n",
    "\n",
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "if \"HF_API_TOKEN\" not in os.environ:\n",
    "    os.environ[\"HF_API_TOKEN\"] = getpass(\"Enter Hugging Face token:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<haystack.core.pipeline.pipeline.Pipeline object at 0x7f4b0aaab550>\n",
       "üöÖ Components\n",
       "  - embedder: SentenceTransformersTextEmbedder\n",
       "  - retriever: InMemoryEmbeddingRetriever\n",
       "  - prompt_builder: PromptBuilder\n",
       "  - llm: OpenAIGenerator\n",
       "üõ§Ô∏è Connections\n",
       "  - embedder.embedding -> retriever.query_embedding (List[float])\n",
       "  - retriever.documents -> prompt_builder.documents (List[Document])\n",
       "  - prompt_builder.prompt -> llm.prompt (str)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from haystack.components.embedders import SentenceTransformersTextEmbedder\n",
    "from haystack.components.retrievers.in_memory import InMemoryEmbeddingRetriever\n",
    "from haystack.components.builders import PromptBuilder\n",
    "from haystack.utils import Secret\n",
    "from haystack.components.generators import OpenAIGenerator\n",
    "\n",
    "template = \"\"\"\n",
    "Answer the questions based on the given context.\n",
    "\n",
    "Context:\n",
    "{% for document in documents %}\n",
    "    {{ document.content }}\n",
    "{% endfor %}\n",
    "\n",
    "Question: {{ question }}\n",
    "Answer:\n",
    "\"\"\"\n",
    "pipe = Pipeline()\n",
    "pipe.add_component(\"embedder\", SentenceTransformersTextEmbedder(model=\"sentence-transformers/all-MiniLM-L6-v2\"))\n",
    "pipe.add_component(\"retriever\", InMemoryEmbeddingRetriever(document_store=document_store))\n",
    "pipe.add_component(\"prompt_builder\", PromptBuilder(template=template))\n",
    "pipe.add_component(\n",
    "    \"llm\",\n",
    "    OpenAIGenerator(\n",
    "        api_key=Secret.from_env_var(\"OPENAI_API_KEY\"),\n",
    "        model=\"gpt-4o-mini-2024-07-18\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "pipe.connect(\"embedder.embedding\", \"retriever.query_embedding\")\n",
    "pipe.connect(\"retriever\", \"prompt_builder.documents\")\n",
    "pipe.connect(\"prompt_builder\", \"llm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81dd4c2ec4c54f14a5ad25ba90c1890b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'llm': {'replies': ['To make vegan keto eggplant lasagna, vegan persimmon flan, and vegan hemp cheese, you would need the following ingredients:\\n\\n**Vegan Keto Eggplant Lasagna:**\\n- 2 large eggplants\\n- Salt (a lot)\\n- 1/2 cup store-bought vegan mozzarella (optional)\\n- **For the Pesto:**\\n  - 4 oz basil\\n  - 1/4 cup almonds\\n  - 1/4 cup nutritional yeast\\n  - 1/4 cup olive oil\\n- **For the Spinach Tofu Ricotta:**\\n  - 14 oz firm or extra firm tofu\\n  - 10 oz spinach\\n  - 1 tsp garlic powder\\n  - Juice of half a lemon\\n  - Salt to taste\\n- **For the Macadamia Nut Cheese:**\\n  - 1 cup macadamia nuts (unsalted, unroasted)\\n  - Juice of 1 lemon\\n  - Garlic powder to taste\\n  - Salt to taste\\n\\n**Vegan Persimmon Flan:**\\n- ¬Ω cup persimmon pulp (strained from 2 average-sized fuyu persimmons)\\n- 1 tbsp cornstarch\\n- ¬Ω tsp agar agar\\n- 1 tbsp agave nectar (or to taste)\\n- 2 tbsp granulated sugar\\n- ¬º cup coconut cream\\n- ¬Ω cup almond milk\\n- ¬Ω tsp vanilla\\n\\n**Vegan Hemp Cheese:**\\n- ¬Ω cup sunflower seeds\\n- ¬Ω cup hemp hearts\\n- 1.5 teaspoons miso paste\\n- 1 tsp nutritional yeast\\n- ¬º cup rejuvelac\\n- 1/4th teaspoon salt (or to taste)\\n\\nMake sure to check if you need additional items like olive oil, which may not be clearly listed in every recipe.'],\n",
       "  'meta': [{'model': 'gpt-4o-mini-2024-07-18',\n",
       "    'index': 0,\n",
       "    'finish_reason': 'stop',\n",
       "    'usage': {'completion_tokens': 378,\n",
       "     'prompt_tokens': 1937,\n",
       "     'total_tokens': 2315,\n",
       "     'completion_tokens_details': CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0),\n",
       "     'prompt_tokens_details': PromptTokensDetails(audio_tokens=0, cached_tokens=0)}}]}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = (\n",
    "    \"What ingredients would I need to make vegan keto eggplant lasagna, vegan persimmon flan, and vegan hemp cheese?\"\n",
    ")\n",
    "\n",
    "pipe.run(\n",
    "    {\n",
    "        \"embedder\": {\"text\": question},\n",
    "        \"prompt_builder\": {\"question\": question}\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_haystack_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
