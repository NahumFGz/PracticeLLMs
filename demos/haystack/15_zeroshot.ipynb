{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Query Classification with TransformersTextRouter and TransformersZeroShotTextRouter](https://haystack.deepset.ai/tutorials/41_query_classification_with_transformerstextrouter_and_transformerszeroshottextrouter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! Solo es para haystack sepa que tutorial se esta ejecutando\n",
    "from haystack.telemetry import tutorial_running\n",
    "tutorial_running(41)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Probando TransformersTextRouter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0700432797a54f09990bac64c8adb831",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/619 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2ba3affce714b3b8dce3d7e664dfdd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/44.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e3fecacfcab4bac9d92d094704c101a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/334 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "320b6b4fd51341e6898bea9472f579e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "338c19709b6047a69fa013cae484ece7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "from haystack.components.routers import TransformersTextRouter\n",
    "\n",
    "text_router = TransformersTextRouter(model=\"shahrukhx01/bert-mini-finetune-question-detection\")\n",
    "text_router.warm_up()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nahumfg/GithubProjects/TesisMaestria/TesisHaystack/venv_haystack_ai/lib/python3.11/site-packages/transformers/pipelines/text_classification.py:106: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'LABEL_0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries = [\n",
    "    \"Arya Stark father\",  # Keyword Query\n",
    "    \"Who was the father of Arya Stark\",  # Interrogative Query\n",
    "    \"Lord Eddard was the father of Arya Stark\",  # Statement Query\n",
    "]\n",
    "\n",
    "result = text_router.run(text=queries[0])\n",
    "next(iter(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query</th>\n",
       "      <th>Output Branch</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arya Stark father</td>\n",
       "      <td>LABEL_0</td>\n",
       "      <td>Keyword Query</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Who was the father of Arya Stark</td>\n",
       "      <td>LABEL_1</td>\n",
       "      <td>Question/Statement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lord Eddard was the father of Arya Stark</td>\n",
       "      <td>LABEL_1</td>\n",
       "      <td>Question/Statement</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Query Output Branch               Class\n",
       "0                         Arya Stark father       LABEL_0       Keyword Query\n",
       "1          Who was the father of Arya Stark       LABEL_1  Question/Statement\n",
       "2  Lord Eddard was the father of Arya Stark       LABEL_1  Question/Statement"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results = {\"Query\": [], \"Output Branch\": [], \"Class\": []}\n",
    "\n",
    "for query in queries:\n",
    "    result = text_router.run(text=query)\n",
    "    results[\"Query\"].append(query)\n",
    "    results[\"Output Branch\"].append(next(iter(result)))\n",
    "    results[\"Class\"].append(\"Keyword Query\" if next(iter(result)) == \"LABEL_0\" else \"Question/Statement\")\n",
    "\n",
    "pd.DataFrame.from_dict(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99f7d3a70f4f4fa2a4f27d4769912a8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/619 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6af495527a554bdb9168c55cd1f3490d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/44.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd25805bd047486fa670f04d15d889c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/334 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01a00046d2e14d7a84ef7040e1b140cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c21a6af0aa594971ad3282aa60161b79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "/home/nahumfg/GithubProjects/TesisMaestria/TesisHaystack/venv_haystack_ai/lib/python3.11/site-packages/transformers/pipelines/text_classification.py:106: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query</th>\n",
       "      <th>Output Branch</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Who was the father of Arya Stark</td>\n",
       "      <td>LABEL_1</td>\n",
       "      <td>Question</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lord Eddard was the father of Arya Stark</td>\n",
       "      <td>LABEL_0</td>\n",
       "      <td>Statement</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Query Output Branch      Class\n",
       "0          Who was the father of Arya Stark       LABEL_1   Question\n",
       "1  Lord Eddard was the father of Arya Stark       LABEL_0  Statement"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A continuaci√≥n, ilustrar√° una pregunta frente a una afirmaci√≥n con TransformersTextRouter usando shahrukhx01/question-vs-statement-classifier . Para esta tarea, debe inicializar un nuevo enrutador de texto con este modelo de clasificaci√≥n.\n",
    "\n",
    "text_router = TransformersTextRouter(model=\"shahrukhx01/question-vs-statement-classifier\")\n",
    "text_router.warm_up()\n",
    "\n",
    "queries = [\n",
    "    \"Who was the father of Arya Stark\",  # Interrogative Query\n",
    "    \"Lord Eddard was the father of Arya Stark\",  # Statement Query\n",
    "]\n",
    "\n",
    "results = {\"Query\": [], \"Output Branch\": [], \"Class\": []}\n",
    "\n",
    "for query in queries:\n",
    "    result = text_router.run(text=query)\n",
    "    results[\"Query\"].append(query)\n",
    "    results[\"Output Branch\"].append(next(iter(result)))\n",
    "    results[\"Class\"].append(\"Question\" if next(iter(result)) == \"LABEL_1\" else \"Statement\")\n",
    "\n",
    "pd.DataFrame.from_dict(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Casos de uso personalizados para la clasificaci√≥n de texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd84aedbf3b54004a97ac2479606bd00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/747 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec8bebea919a4e28936f57a4ea4d0e88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb51d254c7be4b4d94650ae3dda22b56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4a896031b6e46f38b2dd53108392d44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eca67134d61c47d58eb60af5019184a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/150 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "text_router = TransformersTextRouter(model=\"cardiffnlp/twitter-roberta-base-sentiment\")\n",
    "text_router.warm_up()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nahumfg/GithubProjects/TesisMaestria/TesisHaystack/venv_haystack_ai/lib/python3.11/site-packages/transformers/pipelines/text_classification.py:106: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query</th>\n",
       "      <th>Output Branch</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What's the answer?</td>\n",
       "      <td>LABEL_1</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Would you be so lovely to tell me the answer?</td>\n",
       "      <td>LABEL_2</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Can you give me the damn right answer for once??</td>\n",
       "      <td>LABEL_0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Query Output Branch     Class\n",
       "0                                What's the answer?       LABEL_1   neutral\n",
       "1     Would you be so lovely to tell me the answer?       LABEL_2  positive\n",
       "2  Can you give me the damn right answer for once??       LABEL_0  negative"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries = [\n",
    "    \"What's the answer?\",  # neutral query\n",
    "    \"Would you be so lovely to tell me the answer?\",  # positive query\n",
    "    \"Can you give me the damn right answer for once??\",  # negative query\n",
    "]\n",
    "\n",
    "sent_results = {\"Query\": [], \"Output Branch\": [], \"Class\": []}\n",
    "for query in queries:\n",
    "    result = text_router.run(text=query)\n",
    "    sent_results[\"Query\"].append(query)\n",
    "    sent_results[\"Output Branch\"].append(next(iter(result)))\n",
    "    sent_results[\"Class\"].append({\"LABEL_0\": \"negative\", \"LABEL_1\": \"neutral\", \"LABEL_2\":\"positive\"}.get(next(iter(result)), \"Unknown\"))\n",
    "\n",
    "pd.DataFrame.from_dict(sent_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Clasificaci√≥n Zero-Shot con TransformersZeroShotTextRoute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a95639aec3d84b9ca1956fb5bd659868",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.02k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86aab35750f340eab04456c524680161",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/369M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afcc57a8d79d4b9295759213dd880637",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.28k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb298145fcf14c999596759c2acda609",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b07f57ddd0254e958f42d63267752991",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/8.66M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ff485867ed443f6adf5481ded0b314f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/23.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "875c4f526c2545afafbc9c761b071b52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/286 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "from haystack.components.routers import TransformersZeroShotTextRouter\n",
    "\n",
    "text_router = TransformersZeroShotTextRouter(labels=[\"music\", \"cinema\"])\n",
    "text_router.warm_up()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query</th>\n",
       "      <th>Output Branch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In which films does John Travolta appear?</td>\n",
       "      <td>cinema</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the Rolling Stones first album?</td>\n",
       "      <td>music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Who was Sergio Leone?</td>\n",
       "      <td>cinema</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Query Output Branch\n",
       "0  In which films does John Travolta appear?        cinema\n",
       "1    What is the Rolling Stones first album?         music\n",
       "2                      Who was Sergio Leone?        cinema"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries = [\n",
    "    \"In which films does John Travolta appear?\",  # cinema\n",
    "    \"What is the Rolling Stones first album?\",  # music\n",
    "    \"Who was Sergio Leone?\",  # cinema\n",
    "]\n",
    "\n",
    "\n",
    "sent_results = {\"Query\": [], \"Output Branch\": []}\n",
    "for query in queries:\n",
    "    result = text_router.run(text=query)\n",
    "    sent_results[\"Query\"].append(query)\n",
    "    sent_results[\"Output Branch\"].append(next(iter(result)))\n",
    "\n",
    "pd.DataFrame.from_dict(sent_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Query</th>\n",
       "      <th>Output Branch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Who was the father of Arya Stark</td>\n",
       "      <td>Game of Thrones</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Who was the father of Luke Skywalker</td>\n",
       "      <td>Star Wars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Who was the father of Frodo Baggins</td>\n",
       "      <td>Lord of the Rings</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Query      Output Branch\n",
       "0      Who was the father of Arya Stark    Game of Thrones\n",
       "1  Who was the father of Luke Skywalker          Star Wars\n",
       "2   Who was the father of Frodo Baggins  Lord of the Rings"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# De manera similar al ejemplo anterior, podemos utilizar la clasificaci√≥n de texto de tipo zero-shot para agrupar las preguntas en preguntas relacionadas con ‚ÄúJuego de Tronos‚Äù, ‚ÄúStar Wars‚Äù y ‚ÄúEl Se√±or de los Anillos‚Äù. ¬°T√∫ decides la cantidad de etiquetas!\n",
    "\n",
    "from haystack.components.routers import TransformersZeroShotTextRouter\n",
    "\n",
    "text_router = TransformersZeroShotTextRouter(labels=[\"Game of Thrones\", \"Star Wars\", \"Lord of the Rings\"])\n",
    "text_router.warm_up()\n",
    "\n",
    "queries = [\n",
    "    \"Who was the father of Arya Stark\",  # Game of Thrones\n",
    "    \"Who was the father of Luke Skywalker\",  # Star Wars\n",
    "    \"Who was the father of Frodo Baggins\",  # Lord of the Rings\n",
    "]\n",
    "\n",
    "results = {\"Query\": [], \"Output Branch\": []}\n",
    "\n",
    "for query in queries:\n",
    "    result = text_router.run(text=query)\n",
    "    results[\"Query\"].append(query)\n",
    "    results[\"Output Branch\"].append(next(iter(result)))\n",
    "\n",
    "pd.DataFrame.from_dict(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Clasificaci√≥n de consultas por palabras clave o preguntas o declaraciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from haystack.document_stores.in_memory import InMemoryDocumentStore\n",
    "\n",
    "document_store = InMemoryDocumentStore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener los datos\n",
    "from datasets import load_dataset\n",
    "from haystack import Document\n",
    "\n",
    "dataset = load_dataset(\"bilgeyucel/seven-wonders\", split=\"train\")\n",
    "docs = [Document(content=doc[\"content\"], meta=doc[\"meta\"]) for doc in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nahumfg/GithubProjects/TesisMaestria/TesisHaystack/venv_haystack_ai/lib/python3.11/site-packages/sentence_transformers/SentenceTransformer.py:195: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v4 of SentenceTransformers.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Initalize a Document Embedder\n",
    "from haystack.components.embedders import SentenceTransformersDocumentEmbedder\n",
    "\n",
    "doc_embedder = SentenceTransformersDocumentEmbedder(model=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "doc_embedder.warm_up()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "520ebbd4a2dc4457b863f269c61f95d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "151"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Escribir documentos en DocumentStore\n",
    "docs_with_embeddings = doc_embedder.run(docs)\n",
    "document_store.write_documents(docs_with_embeddings[\"documents\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Initialize Retrievers, TextEmbedder and TransformersTextRouter\n",
    "from haystack.components.retrievers.in_memory import InMemoryBM25Retriever, InMemoryEmbeddingRetriever\n",
    "from haystack.components.embedders import SentenceTransformersTextEmbedder\n",
    "from haystack.components.joiners import DocumentJoiner\n",
    "\n",
    "text_router = TransformersTextRouter(model=\"shahrukhx01/bert-mini-finetune-question-detection\")\n",
    "text_embedder = SentenceTransformersTextEmbedder(model=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "embedding_retriever = InMemoryEmbeddingRetriever(document_store)\n",
    "bm25_retriever = InMemoryBM25Retriever(document_store)\n",
    "document_joiner = DocumentJoiner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<haystack.core.pipeline.pipeline.Pipeline object at 0x7f7e1f781150>\n",
       "üöÖ Components\n",
       "  - text_router: TransformersTextRouter\n",
       "  - text_embedder: SentenceTransformersTextEmbedder\n",
       "  - embedding_retriever: InMemoryEmbeddingRetriever\n",
       "  - bm25_retriever: InMemoryBM25Retriever\n",
       "  - document_joiner: DocumentJoiner\n",
       "üõ§Ô∏è Connections\n",
       "  - text_router.LABEL_0 -> text_embedder.text (str)\n",
       "  - text_router.LABEL_1 -> bm25_retriever.query (str)\n",
       "  - text_embedder.embedding -> embedding_retriever.query_embedding (List[float])\n",
       "  - embedding_retriever.documents -> document_joiner.documents (List[Document])\n",
       "  - bm25_retriever.documents -> document_joiner.documents (List[Document])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3) Definir el pipeline\n",
    "from haystack import Pipeline\n",
    "\n",
    "query_classification_pipeline = Pipeline()\n",
    "query_classification_pipeline.add_component(\"text_router\", text_router)\n",
    "query_classification_pipeline.add_component(\"text_embedder\", text_embedder)\n",
    "query_classification_pipeline.add_component(\"embedding_retriever\", embedding_retriever)\n",
    "query_classification_pipeline.add_component(\"bm25_retriever\", bm25_retriever)\n",
    "query_classification_pipeline.add_component(\"document_joiner\", document_joiner)\n",
    "\n",
    "query_classification_pipeline.connect(\"text_router.LABEL_0\", \"text_embedder\")\n",
    "query_classification_pipeline.connect(\"text_embedder\", \"embedding_retriever\")\n",
    "query_classification_pipeline.connect(\"text_router.LABEL_1\", \"bm25_retriever\")\n",
    "query_classification_pipeline.connect(\"bm25_retriever\", \"document_joiner\")\n",
    "query_classification_pipeline.connect(\"embedding_retriever\", \"document_joiner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==============================\n",
      "QUESTION QUERY RESULTS\n",
      "==============================\n",
      "{'document_joiner': {'documents': [Document(id=4c82325818ccd91af8d68fec37108ce7a93696392f315bd0497ad3a8903d0b45, content: 'The Masonic House of the Temple of the Scottish Rite, Washington, DC, designed by John Russell Pope,...', meta: {'url': 'https://en.wikipedia.org/wiki/Mausoleum_at_Halicarnassus', '_split_id': 18}, score: 8.192663165691801, embedding: vector of size 384), Document(id=4a988f268c10bbb6af9a18063a14460b7e0126c7ed1befb2be17c9cbbc4bb064, content: 'The earliest pharaonic name of seal impressions is that of Khufu, the latest of Pepi II. Worker graf...', meta: {'url': 'https://en.wikipedia.org/wiki/Great_Pyramid_of_Giza', '_split_id': 4}, score: 6.652366985087608, embedding: vector of size 384), Document(id=9c1d7b92058a18bd101c037c87519e9225983c1dbb9386d51412895d5101d096, content: '[68]\n",
      "The most notable account of this legend was given by Al-Masudi (896‚Äì956) in his Akbar al-zaman,...', meta: {'url': 'https://en.wikipedia.org/wiki/Great_Pyramid_of_Giza', '_split_id': 19}, score: 5.365566894478934, embedding: vector of size 384), Document(id=1ac6d4aedca0f952d87a1cfd4d4bde946d54f103a8f802419671d9ad2e26f3bc, content: '[21] However, the gardens were said to still exist at the time that later writers described them, an...', meta: {'url': 'https://en.wikipedia.org/wiki/Hanging_Gardens_of_Babylon', '_split_id': 5}, score: 5.279086706756248, embedding: vector of size 384), Document(id=975a20d36be68ebf6c7c7a37012dd0deff29797201dddb21e1b3a25c29b168e2, content: 'Modern historians have pointed out that two years would not be enough time to decorate and build suc...', meta: {'url': 'https://en.wikipedia.org/wiki/Mausoleum_at_Halicarnassus', '_split_id': 5}, score: 4.983734342490586, embedding: vector of size 384), Document(id=5d02e37e955d05869cad244b01e9c458c0676a736390b04f347390aa6d8236f7, content: 'The passage is 2¬†cubits (1.0¬†m; 3.4¬†ft) wide and 1.17¬†m (3.8¬†ft) high for most of its length, but ne...', meta: {'url': 'https://en.wikipedia.org/wiki/Great_Pyramid_of_Giza', '_split_id': 45}, score: 4.9689671066012755, embedding: vector of size 384), Document(id=06ce9e11253c0c619159c6bd9c8f8e711d7a841025efc696e07b74000c5f750a, content: 'The remains were described briefly by Strabo (64 or 63¬†BC ‚Äì c. 24¬†AD), in his work Geography (Book X...', meta: {'url': 'https://en.wikipedia.org/wiki/Colossus_of_Rhodes', '_split_id': 6}, score: 4.956812213009003, embedding: vector of size 384), Document(id=8898fdd9ba5e7049fcec94ae5e9f172337de969977ccbfb1d5e2b23baf964d15, content: 'Only Josephus names Nebuchadnezzar as the king who built the gardens; although Nebuchadnezzar left m...', meta: {'url': 'https://en.wikipedia.org/wiki/Hanging_Gardens_of_Babylon', '_split_id': 7}, score: 4.950459961177993, embedding: vector of size 384), Document(id=e42388e23323dad64d9cd5dd5e93fa1391d93be3dc161236d789e2eb7de99546, content: 'These were entrusted to a boat builder, Haj Ahmed Yusuf, who worked out how the pieces fit together....', meta: {'url': 'https://en.wikipedia.org/wiki/Great_Pyramid_of_Giza', '_split_id': 60}, score: 4.917705216995133, embedding: vector of size 384), Document(id=417cb72c998c669851f4cfc8b4a2ba75c7ab8fd2e880f53ea10e6c75d8e0a6b2, content: 'Further, he describes a method discovered by Thales of Miletus for ascertaining the pyramid's height...', meta: {'url': 'https://en.wikipedia.org/wiki/Great_Pyramid_of_Giza', '_split_id': 17}, score: 4.9033381526508935, embedding: vector of size 384)]}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nahumfg/GithubProjects/TesisMaestria/TesisHaystack/venv_haystack_ai/lib/python3.11/site-packages/transformers/pipelines/text_classification.py:106: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1614d61fef2c40b1b77f70c9731d2c6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==============================\n",
      "KEYWORD QUERY RESULTS\n",
      "==============================\n",
      "{'document_joiner': {'documents': [Document(id=8d83c5906c44567371940fa0a00dfd5da94a2f0e93001c08013fa21978705df4, content: 'Conquest[edit]\n",
      "In the 4th century BC, Halicarnassus was the capital of a small regional kingdom of C...', meta: {'url': 'https://en.wikipedia.org/wiki/Mausoleum_at_Halicarnassus', '_split_id': 1}, score: 0.22343472174809592), Document(id=15ba19be181b99cedeada16c282ea812d83b35f744ea5066530d40fbf784546c, content: 'Various sources describe this as a vainglorious act of arson by a man, Herostratus, who set fire to ...', meta: {'url': 'https://en.wikipedia.org/wiki/Temple_of_Artemis', '_split_id': 6}, score: 0.1953121461798527), Document(id=de0480cf304ee42ec382ba29752d16015e5b656e84a59518afe59549643e77cc, content: 'In the 7th century BC, a flood[7] destroyed the temple, depositing over half a meter of sand and flo...', meta: {'url': 'https://en.wikipedia.org/wiki/Temple_of_Artemis', '_split_id': 3}, score: 0.18115355996707005), Document(id=7737c2c1fc7a9f9950e56e43d614ad1746670b1e37f1c2fbac7fd104b273ffc4, content: 'The literary accounts that describe it as \"Amazonian\" refer to the later founder-myths of Greek emig...', meta: {'url': 'https://en.wikipedia.org/wiki/Temple_of_Artemis', '_split_id': 12}, score: 0.17979598830969729), Document(id=9322c40ad7441344c8e0d35c142949b4d7241e70e90fa313b2d928d4fae014db, content: 'Lynn LiDonnici observes that modern scholars are likely to be more concerned with origins of the Lad...', meta: {'url': 'https://en.wikipedia.org/wiki/Temple_of_Artemis', '_split_id': 18}, score: 0.17161407904808437), Document(id=f736d7b87b1e0b18d32a823cacc82df7773fd3e6437b6d3e6b1dfd9b49dd80e6, content: 'Sennacherib was proud of the technologies he had employed and describes them in some detail on his i...', meta: {'url': 'https://en.wikipedia.org/wiki/Hanging_Gardens_of_Babylon', '_split_id': 9}, score: 0.16156529418269705), Document(id=29298f630a7bcda1c8daf46301f0147b20b35161cc9957b75e3fe928734ebd4a, content: 'The Greek habits of syncretism assimilated all foreign gods under some form of the Olympian pantheon...', meta: {'url': 'https://en.wikipedia.org/wiki/Temple_of_Artemis', '_split_id': 17}, score: 0.16046026981988837), Document(id=fa80203b62ba10ac5bb75f24bf06c993cd06669a58f53b9a0f28f026250e359f, content: 'Inside the vessel was \"something like pitch,\" and when the explorer reached into the vessel \"a gold ...', meta: {'url': 'https://en.wikipedia.org/wiki/Great_Pyramid_of_Giza', '_split_id': 20}, score: 0.1525240405000092), Document(id=785075351ac84affb97aca27041e4a412e2e7ac7b3a03c986b5ca6fdd386425c, content: '[36] There was a tradition of Assyrian royal garden building. King Ashurnasirpal II (883‚Äì859 BC) had...', meta: {'url': 'https://en.wikipedia.org/wiki/Hanging_Gardens_of_Babylon', '_split_id': 8}, score: 0.14819718411215294), Document(id=48d2265b04561ff9bd0558ed960fa85d2d0c5dcde0fa2710c3d7e06ee040e610, content: 'In 653, an Arab force under Muslim general Muawiyah I raided Rhodes, and according to the Chronicle ...', meta: {'url': 'https://en.wikipedia.org/wiki/Colossus_of_Rhodes', '_split_id': 10}, score: 0.1481505898368326)]}}\n"
     ]
    }
   ],
   "source": [
    "# 4) Ejecutar el pipeline\n",
    "# Useful for framing headers\n",
    "equal_line = \"=\" * 30\n",
    "\n",
    "# Run only the dense retriever on the full sentence query\n",
    "res_1 = query_classification_pipeline.run({\"text_router\": {\"text\": \"Who is the father of Arya Stark?\"}})\n",
    "print(f\"\\n\\n{equal_line}\\nQUESTION QUERY RESULTS\\n{equal_line}\")\n",
    "print(res_1)\n",
    "\n",
    "# Run only the sparse retriever on a keyword based query\n",
    "res_2 = query_classification_pipeline.run({\"text_router\": {\"text\": \"arya stark father\"}})\n",
    "print(f\"\\n\\n{equal_line}\\nKEYWORD QUERY RESULTS\\n{equal_line}\")\n",
    "print(res_2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Pipeline with Question vs. Statement Query Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<haystack.core.pipeline.pipeline.Pipeline object at 0x7f7e332f5d50>\n",
       "üöÖ Components\n",
       "  - bm25_retriever_0: InMemoryBM25Retriever\n",
       "  - bm25_retriever_1: InMemoryBM25Retriever\n",
       "  - text_router: TransformersTextRouter\n",
       "  - reader: ExtractiveReader\n",
       "üõ§Ô∏è Connections\n",
       "  - bm25_retriever_0.documents -> reader.documents (List[Document])\n",
       "  - text_router.LABEL_0 -> bm25_retriever_0.query (str)\n",
       "  - text_router.LABEL_1 -> bm25_retriever_1.query (str)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1) Definir la tuber√≠a y los componentes\n",
    "from haystack.components.readers import ExtractiveReader\n",
    "\n",
    "query_classification_pipeline = Pipeline()\n",
    "query_classification_pipeline.add_component(\"bm25_retriever_0\", InMemoryBM25Retriever(document_store))\n",
    "query_classification_pipeline.add_component(\"bm25_retriever_1\", InMemoryBM25Retriever(document_store))\n",
    "query_classification_pipeline.add_component(\"text_router\", TransformersTextRouter(model=\"shahrukhx01/question-vs-statement-classifier\"))\n",
    "query_classification_pipeline.add_component(\"reader\", ExtractiveReader())\n",
    "\n",
    "query_classification_pipeline.connect(\"text_router.LABEL_0\", \"bm25_retriever_0\")\n",
    "query_classification_pipeline.connect(\"bm25_retriever_0\", \"reader\")\n",
    "query_classification_pipeline.connect(\"text_router.LABEL_1\", \"bm25_retriever_1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==============================\n",
      "QUESTION QUERY RESULTS\n",
      "==============================\n",
      "{'bm25_retriever_1': {'documents': [Document(id=4c82325818ccd91af8d68fec37108ce7a93696392f315bd0497ad3a8903d0b45, content: 'The Masonic House of the Temple of the Scottish Rite, Washington, DC, designed by John Russell Pope,...', meta: {'url': 'https://en.wikipedia.org/wiki/Mausoleum_at_Halicarnassus', '_split_id': 18}, score: 8.192663165691801, embedding: vector of size 384), Document(id=4a988f268c10bbb6af9a18063a14460b7e0126c7ed1befb2be17c9cbbc4bb064, content: 'The earliest pharaonic name of seal impressions is that of Khufu, the latest of Pepi II. Worker graf...', meta: {'url': 'https://en.wikipedia.org/wiki/Great_Pyramid_of_Giza', '_split_id': 4}, score: 6.652366985087608, embedding: vector of size 384), Document(id=9c1d7b92058a18bd101c037c87519e9225983c1dbb9386d51412895d5101d096, content: '[68]\n",
      "The most notable account of this legend was given by Al-Masudi (896‚Äì956) in his Akbar al-zaman,...', meta: {'url': 'https://en.wikipedia.org/wiki/Great_Pyramid_of_Giza', '_split_id': 19}, score: 5.365566894478934, embedding: vector of size 384), Document(id=1ac6d4aedca0f952d87a1cfd4d4bde946d54f103a8f802419671d9ad2e26f3bc, content: '[21] However, the gardens were said to still exist at the time that later writers described them, an...', meta: {'url': 'https://en.wikipedia.org/wiki/Hanging_Gardens_of_Babylon', '_split_id': 5}, score: 5.279086706756248, embedding: vector of size 384), Document(id=975a20d36be68ebf6c7c7a37012dd0deff29797201dddb21e1b3a25c29b168e2, content: 'Modern historians have pointed out that two years would not be enough time to decorate and build suc...', meta: {'url': 'https://en.wikipedia.org/wiki/Mausoleum_at_Halicarnassus', '_split_id': 5}, score: 4.983734342490586, embedding: vector of size 384), Document(id=5d02e37e955d05869cad244b01e9c458c0676a736390b04f347390aa6d8236f7, content: 'The passage is 2¬†cubits (1.0¬†m; 3.4¬†ft) wide and 1.17¬†m (3.8¬†ft) high for most of its length, but ne...', meta: {'url': 'https://en.wikipedia.org/wiki/Great_Pyramid_of_Giza', '_split_id': 45}, score: 4.9689671066012755, embedding: vector of size 384), Document(id=06ce9e11253c0c619159c6bd9c8f8e711d7a841025efc696e07b74000c5f750a, content: 'The remains were described briefly by Strabo (64 or 63¬†BC ‚Äì c. 24¬†AD), in his work Geography (Book X...', meta: {'url': 'https://en.wikipedia.org/wiki/Colossus_of_Rhodes', '_split_id': 6}, score: 4.956812213009003, embedding: vector of size 384), Document(id=8898fdd9ba5e7049fcec94ae5e9f172337de969977ccbfb1d5e2b23baf964d15, content: 'Only Josephus names Nebuchadnezzar as the king who built the gardens; although Nebuchadnezzar left m...', meta: {'url': 'https://en.wikipedia.org/wiki/Hanging_Gardens_of_Babylon', '_split_id': 7}, score: 4.950459961177993, embedding: vector of size 384), Document(id=e42388e23323dad64d9cd5dd5e93fa1391d93be3dc161236d789e2eb7de99546, content: 'These were entrusted to a boat builder, Haj Ahmed Yusuf, who worked out how the pieces fit together....', meta: {'url': 'https://en.wikipedia.org/wiki/Great_Pyramid_of_Giza', '_split_id': 60}, score: 4.917705216995133, embedding: vector of size 384), Document(id=417cb72c998c669851f4cfc8b4a2ba75c7ab8fd2e880f53ea10e6c75d8e0a6b2, content: 'Further, he describes a method discovered by Thales of Miletus for ascertaining the pyramid's height...', meta: {'url': 'https://en.wikipedia.org/wiki/Great_Pyramid_of_Giza', '_split_id': 17}, score: 4.9033381526508935, embedding: vector of size 384)]}}\n",
      "\n",
      "\n",
      "==============================\n",
      "KEYWORD QUERY RESULTS\n",
      "==============================\n",
      "{'reader': {'answers': [ExtractedAnswer(query='Arya Stark was the daughter of a Lord', score=0.36549925804138184, data='King of Upper and Lower Egypt Khufu', document=Document(id=4a988f268c10bbb6af9a18063a14460b7e0126c7ed1befb2be17c9cbbc4bb064, content: 'The earliest pharaonic name of seal impressions is that of Khufu, the latest of Pepi II. Worker graf...', meta: {'url': 'https://en.wikipedia.org/wiki/Great_Pyramid_of_Giza', '_split_id': 4}, score: 8.527383694416635, embedding: vector of size 384), context=None, document_offset=ExtractedAnswer.Span(start=518, end=553), context_offset=None, meta={}), ExtractedAnswer(query='Arya Stark was the daughter of a Lord', score=0.3226391673088074, data=\"Phidias' workshop at Olympia\\nPhidias' workshop\", document=Document(id=60469411be57782b4a518ee430379e5235c5dff6f279fe232fae0adfb840644d, content: 'The 11th-century Byzantine historian Georgios Kedrenos records a tradition that it was carried off t...', meta: {'url': 'https://en.wikipedia.org/wiki/Statue_of_Zeus_at_Olympia', '_split_id': 5}, score: 8.40941628722177, embedding: vector of size 384), context=None, document_offset=ExtractedAnswer.Span(start=698, end=744), context_offset=None, meta={}), ExtractedAnswer(query='Arya Stark was the daughter of a Lord', score=0.29660049080848694, data='\\nPhoto', document=Document(id=60469411be57782b4a518ee430379e5235c5dff6f279fe232fae0adfb840644d, content: 'The 11th-century Byzantine historian Georgios Kedrenos records a tradition that it was carried off t...', meta: {'url': 'https://en.wikipedia.org/wiki/Statue_of_Zeus_at_Olympia', '_split_id': 5}, score: 8.40941628722177, embedding: vector of size 384), context=None, document_offset=ExtractedAnswer.Span(start=681, end=687), context_offset=None, meta={}), ExtractedAnswer(query='Arya Stark was the daughter of a Lord', score=0.29023823142051697, data='\\nConstruction', document=Document(id=055b1454beddf2064ddfd8079da93ddffd5f9a0dfa25fb5321835b914312c32b, content: 'In addition to measuring the structure, alongside the other pyramids at Giza, al-Baghdadi also write...', meta: {'url': 'https://en.wikipedia.org/wiki/Great_Pyramid_of_Giza', '_split_id': 21}, score: 5.86912829515654, embedding: vector of size 384), context=None, document_offset=ExtractedAnswer.Span(start=892, end=905), context_offset=None, meta={}), ExtractedAnswer(query='Arya Stark was the daughter of a Lord', score=0.2845080494880676, data='Lighthouse of Alexandria by Philip Galle; 1572, Rijksmuseum', document=Document(id=09af7baea84fbe125b3321c9fdb851cbe9f3fdc54d5e4f21b2f6e63134882d24, content: 'The Ras el-Tin promontory, where Ras el-Tin Palace was built in the 19th century, represents all tha...', meta: {'url': 'https://en.wikipedia.org/wiki/Lighthouse_of_Alexandria', '_split_id': 2}, score: 5.869676649867554, embedding: vector of size 384), context=None, document_offset=ExtractedAnswer.Span(start=245, end=304), context_offset=None, meta={}), ExtractedAnswer(query='Arya Stark was the daughter of a Lord', score=0.27953222393989563, data='Preparation of the site\\nA hillock forms the base on which the pyramid stands. It was cut back into steps and only a strip around the perimeter was leveled,[78] which has been measured to be horizontal and flat to within 21 millimetres (0.', document=Document(id=055b1454beddf2064ddfd8079da93ddffd5f9a0dfa25fb5321835b914312c32b, content: 'In addition to measuring the structure, alongside the other pyramids at Giza, al-Baghdadi also write...', meta: {'url': 'https://en.wikipedia.org/wiki/Great_Pyramid_of_Giza', '_split_id': 21}, score: 5.86912829515654, embedding: vector of size 384), context=None, document_offset=ExtractedAnswer.Span(start=906, end=1144), context_offset=None, meta={}), ExtractedAnswer(query='Arya Stark was the daughter of a Lord', score=0.2772819399833679, data='Lord Stratford de Redcliffe', document=Document(id=72d9ba5c859a4737ea03759f89a6d4fb50cab7f04061de6c33e1835ef7f8eedf, content: 'Because of this, Fergusson concluded that the building was ruined, probably by an earthquake, betwee...', meta: {'url': 'https://en.wikipedia.org/wiki/Mausoleum_at_Halicarnassus', '_split_id': 6}, score: 8.444858211584728, embedding: vector of size 384), context=None, document_offset=ExtractedAnswer.Span(start=622, end=649), context_offset=None, meta={}), ExtractedAnswer(query='Arya Stark was the daughter of a Lord', score=0.26334047317504883, data='4 horse chariots of marble. The building was accented with both sculptural friezes and free standing figures. \"The free standing figures were arranged on 5 or 6 different levels.\"[9]\\nWe are now able to justify that Pliny\\'s knowledge came from a work written by the architect. It is clear that Pliny did not grasp the design of the mausoleum fully which creates problems in recreating the structure. He does state many facts which help the reader recreate pieces of the puzzle. Other writings by Pausanias, Strabo, and Vitruvius also help us to gather more information about the Mausoleum.[21]\\nAccording to Pliny, the mausoleum was 19 metres (63\\xa0ft) north and south, shorter on other fronts, 125 metres (411\\xa0ft) perimeter, and 25\\xa0cubits (11.', document=Document(id=0b3ec68a3754c399d2160c93c36ea172c318edad9310828c7d056392956f884f, content: 'The building was rectangular, not square, surrounded by a colonnade of thirty-six columns. There was...', meta: {'url': 'https://en.wikipedia.org/wiki/Mausoleum_at_Halicarnassus', '_split_id': 9}, score: 5.870291493549832, embedding: vector of size 384), context=None, document_offset=ExtractedAnswer.Span(start=191, end=931), context_offset=None, meta={}), ExtractedAnswer(query='Arya Stark was the daughter of a Lord', score=0.26177307963371277, data='Antipater of Sidon identified it as one of his Seven Wonders of the Ancient World. It was destroyed by successive earthquakes from the 12th to the 15th century;[6][7][8', document=Document(id=9b6d3d0d9599886ec38a2476e741988900133e6d57056f4d4718976ab7bc8d87, content: 'The Mausoleum at Halicarnassus or Tomb of Mausolus[a] (Ancient Greek: ŒúŒ±œÖœÉœâŒªŒµ·øñŒøŒΩ œÑ·øÜœÇ ·ºâŒªŒπŒ∫Œ±œÅŒΩŒ±œÉœÉŒø·ø¶; T...', meta: {'url': 'https://en.wikipedia.org/wiki/Mausoleum_at_Halicarnassus', '_split_id': 0}, score: 5.870202729262424, embedding: vector of size 384), context=None, document_offset=ExtractedAnswer.Span(start=926, end=1094), context_offset=None, meta={}), ExtractedAnswer(query='Arya Stark was the daughter of a Lord', score=0.2528727352619171, data='Mausolus[a] (Ancient Greek: ŒúŒ±œÖœÉœâŒªŒµ·øñŒøŒΩ œÑ·øÜœÇ ·ºâŒªŒπŒ∫Œ±œÅŒΩŒ±œÉœÉŒø·ø¶; Turkish: Halikarnas Mozolesi) was a tomb built between 353 and 350\\xa0BC in Halicarnassus (present Bodrum, Turkey) for Mausolus, an Anatolian from Caria and a satrap in the Achaemenid Empire, and his sister-wife Artemisia II of Caria', document=Document(id=9b6d3d0d9599886ec38a2476e741988900133e6d57056f4d4718976ab7bc8d87, content: 'The Mausoleum at Halicarnassus or Tomb of Mausolus[a] (Ancient Greek: ŒúŒ±œÖœÉœâŒªŒµ·øñŒøŒΩ œÑ·øÜœÇ ·ºâŒªŒπŒ∫Œ±œÅŒΩŒ±œÉœÉŒø·ø¶; T...', meta: {'url': 'https://en.wikipedia.org/wiki/Mausoleum_at_Halicarnassus', '_split_id': 0}, score: 5.870202729262424, embedding: vector of size 384), context=None, document_offset=ExtractedAnswer.Span(start=42, end=329), context_offset=None, meta={}), ExtractedAnswer(query='Arya Stark was the daughter of a Lord', score=0.24743135273456573, data='Artemis Tapƒ±naƒüƒ±), also known as the Temple of Diana, was a Greek temple dedicated to an ancient, local form of the goddess Artemis (identified with Diana, a Roman goddess). It was located in Ephesus (near the modern town of Sel√ßuk in present-day Turkey). By 401 AD it had been ruined or destroyed.[1] Only foundations and fragments of the last temple remain at the site.\\nThe earliest version of the temple (a Bronze Age temenos) antedated the Ionic immigration by many years. Callimachus, in his Hymn to Artemis, attributed it to the Amazons. In the 7th century BC, it was destroyed by a flood.\\nIts reconstruction, in more grandiose form, began around 550 BC, under Chersiphron, the Cretan architect, and his son Metagenes. The project was funded by Croesus of Lydia, and took 10 years to complete. This version of the temple was destroyed in 356 BC by an arsonist.\\n', document=Document(id=e6244310d1a0686d06b52b93c1d96972a8d01943be7735b6593a0ffadd091b3c, content: 'The Temple of Artemis or Artemision (Greek: ·ºàœÅœÑŒµŒºŒØœÉŒπŒøŒΩ; Turkish: Artemis Tapƒ±naƒüƒ±), also known as th...', meta: {'url': 'https://en.wikipedia.org/wiki/Temple_of_Artemis', '_split_id': 0}, score: 5.868186231095871, embedding: vector of size 384), context=None, document_offset=ExtractedAnswer.Span(start=65, end=932), context_offset=None, meta={}), ExtractedAnswer(query='Arya Stark was the daughter of a Lord', score=0.24727888405323029, data='Sennacherib was proud of the technologies he had employed and describes them in some detail on his inscriptions. At the headwater of Bavian (Khinnis)[39] his inscription mentions automatic sluice gates. An enormous aqueduct crossing the valley at Jerwan was constructed of over two million dressed stones. It used stone arches and waterproof cement.[40] On it is written:\\n\\nSennacherib king of the world king of Assyria', document=Document(id=f736d7b87b1e0b18d32a823cacc82df7773fd3e6437b6d3e6b1dfd9b49dd80e6, content: 'Sennacherib was proud of the technologies he had employed and describes them in some detail on his i...', meta: {'url': 'https://en.wikipedia.org/wiki/Hanging_Gardens_of_Babylon', '_split_id': 9}, score: 5.862567822134554, embedding: vector of size 384), context=None, document_offset=ExtractedAnswer.Span(start=0, end=418), context_offset=None, meta={}), ExtractedAnswer(query='Arya Stark was the daughter of a Lord', score=0.24462208151817322, data='Sennacherib claimed that he had built a \"Wonder for all Peoples\", and said he was the first to deploy a new casting technique in place of the \"lost-wax\" process for his monumental (30 tonne) bronze castings. He was able to bring the water into his garden at a high level because it was sourced from further up in the mountains, and he then raised the water even higher by deploying his new water screws', document=Document(id=f736d7b87b1e0b18d32a823cacc82df7773fd3e6437b6d3e6b1dfd9b49dd80e6, content: 'Sennacherib was proud of the technologies he had employed and describes them in some detail on his i...', meta: {'url': 'https://en.wikipedia.org/wiki/Hanging_Gardens_of_Babylon', '_split_id': 9}, score: 5.862567822134554, embedding: vector of size 384), context=None, document_offset=ExtractedAnswer.Span(start=639, end=1041), context_offset=None, meta={}), ExtractedAnswer(query='Arya Stark was the daughter of a Lord', score=0.2342258095741272, data='Mausolus before his death or continued by the next leaders', document=Document(id=975a20d36be68ebf6c7c7a37012dd0deff29797201dddb21e1b3a25c29b168e2, content: 'Modern historians have pointed out that two years would not be enough time to decorate and build suc...', meta: {'url': 'https://en.wikipedia.org/wiki/Mausoleum_at_Halicarnassus', '_split_id': 5}, score: 5.887070537721882, embedding: vector of size 384), context=None, document_offset=ExtractedAnswer.Span(start=195, end=253), context_offset=None, meta={}), ExtractedAnswer(query='Arya Stark was the daughter of a Lord', score=0.2264714390039444, data='Eustathius, writing in the 12th century on his commentary of the Iliad, says \"it was and is a wonder', document=Document(id=975a20d36be68ebf6c7c7a37012dd0deff29797201dddb21e1b3a25c29b168e2, content: 'Modern historians have pointed out that two years would not be enough time to decorate and build suc...', meta: {'url': 'https://en.wikipedia.org/wiki/Mausoleum_at_Halicarnassus', '_split_id': 5}, score: 5.887070537721882, embedding: vector of size 384), context=None, document_offset=ExtractedAnswer.Span(start=900, end=1000), context_offset=None, meta={}), ExtractedAnswer(query='Arya Stark was the daughter of a Lord', score=0.008232428295270591, data=None, document=None, context=None, document_offset=None, context_offset=None, meta={})]}}\n"
     ]
    }
   ],
   "source": [
    "# 2) Ejecutar el pipeline\n",
    "# Useful for framing headers\n",
    "equal_line = \"=\" * 30\n",
    "\n",
    "# Run the retriever + reader on the question query\n",
    "query = \"Who is the father of Arya Stark?\"\n",
    "res_1 = query_classification_pipeline.run({\"text_router\": {\"text\": query}, \"reader\": {\"query\": query}})\n",
    "print(f\"\\n\\n{equal_line}\\nQUESTION QUERY RESULTS\\n{equal_line}\")\n",
    "print(res_1)\n",
    "\n",
    "# Run only the retriever on the statement query\n",
    "query = \"Arya Stark was the daughter of a Lord\"\n",
    "res_2 = query_classification_pipeline.run({\"text_router\": {\"text\": query}, \"reader\": {\"query\": query}})\n",
    "print(f\"\\n\\n{equal_line}\\nKEYWORD QUERY RESULTS\\n{equal_line}\")\n",
    "print(res_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_haystack_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
